# 注意事项

## 通过 Slurm 系统使用 GPU 资源！

请参考[这里](https://co1lin.github.io/AIR-Server-Doc/gpu/)。

## 磁盘配额

服务器部署了中心化的存储节点 `air-storage` ，并通过NFS挂载在所有机器的 `/home` 目录下。

目前，各个实验室在使用存储时均有 `9216G` 的软配额与 `10240G` 的硬配额。当存储使用量超过软配额时，有 3 天的过渡时间将存储使用量下降到配额内；当存储使用量超过软配额 3 天，或存储使用量超过硬配额，用户将不能再向磁盘写入更多数据。

```shell
# 查看当前用户组的磁盘配额
ssh air-storage quota -gs
```

## 提醒

### 做好宕机发生的准备

我们尽可能保证服务器高可用运行，服务器仍然有极小概率宕机。

为了实验数据以及进度的安全，请做好包括但不限于以下几种准备：

1. 使用 GitHub 等平台云端托管代码，防止硬盘损坏造成代码丢失。
2. 在跑实验时适度保存 checkpoints ，以在宕机等意外发生之后能快速恢复到之前的实验状态。

### 配置虚拟环境

为了服务器平稳运行，请联系管理员安装 `apt` 源中的软件包。

常用 Python 环境依赖可以通过创建 [conda 环境](conda)来满足；用户可以在虚拟环境中通过 `conda` 或 `pip` 安装所需的 Python 依赖。

NVIDIA GPU 底层驱动以及 CUDA Toolkit 已经安装好了。遵循一般惯例， CUDA 的安装路径在 `/usr/local` 下，如 `/usr/local/cuda` （默认版本），或者 `/usr/local/cuda11.1` （特定版本）。使用时只需根据这个路径信息配置好环境变量（通常为 `CUDA_HOME` ）即可。

 `/home/share` 目录下有一些已下载的 `whl` 文件，可以直接通过 `pip install` 安装至虚拟环境的安装包。如果满足需求可以直接安装至自己的环境使用。

### 调试机不保证程序不被中断

调试机仅供代码运行前调试，正式运行任务请提交 Slurm 系统执行。

为保证调试机可用，调试机上的程序出现异常时（异常高的 CPU 、内存、 IO 占用），管理员将在**不通知用户**的情况下终止该进程。另外，当可用内存低于 10% 时，内存占用最多的进程将被系统**自动杀死**。
