# 注意事项

## 通过 Slurm 系统使用 GPU 资源！

请参考[这里](https://co1lin.github.io/AIR-Server-Doc/gpu/)。

## 磁盘配额

服务器部署了中心化的存储节点`air-storage`，并通过NFS挂载在所有机器的`/home`目录下。

目前，各个实验室在使用存储时均有`3000G`的软配额与`5000G`的硬配额。当存储使用量超过软配额时，有7天的过渡时间将存储使用量下降到配额内；当存储使用量超过软配额7天，或存储使用量超过硬配额，用户将不能再向磁盘写入更多数据。

```shell
# 查看当前用户组的磁盘配额
ssh air-storage quota -gs
```

## 做好宕机等灾难发生的准备

我们尽可能保证服务器的高可靠性，但是我们并不能保证服务器永不宕机。

为了实验数据以及进度的安全，请做好包括但不限于以下几种准备：

1. 使用 GitHub 等平台云端托管代码，防止硬盘损坏造成代码丢失。
2. 在跑实验时适度保存 checkpoints ，以在宕机等意外发生之后能快速恢复到之前的实验状态。


## 实验环境

为了避免对服务器环境造成破坏，用户没有在集群上通过 `apt` 安装软件包的权限。

一般机器学习所需的 Python 环境可以通过每个用户创建自己的 [conda 环境](conda)来满足；用户可以在自己的虚拟环境通过 `conda` 或 `pip` 安装所需的 Python 包。

NVIDIA GPU 底层驱动以及 CUDA Toolkit 已经安装好了。遵循一般惯例， CUDA 的安装路径在 `/usr/local` 下，如 `/usr/local/cuda` （默认版本），或者 `/usr/local/cuda11.1` （特定版本）。使用时只需根据这个路径信息配置好环境变量（通常为 `CUDA_HOME` ）即可。

PyTorch 和其它包一样，在每个实验中的版本都可能不同，因此请在自己的环境中自行安装。在 `/home/share` 目录下有一些已下载的 `whl` 文件，可以直接通过 `pip install` 安装至虚拟环境的安装包；如果满足需求可以直接安装至自己的环境使用。

## 内存占用较大可能会被终止

为了避免阻塞操作，集群中的跳板机上部署了 [earlyoom - The Early OOM Daemon](https://github.com/rfjakob/earlyoom) 避免内存占用过多。

如果在跳板机上测试程序，请注意当可用内存低于 10% 时，内存占用最多的进程将被杀死。

如果使用 Slurm 系统中跳板机，每申请一张 GPU 会配给 20GB 的内存，使用超出配给内存的任务将被杀死。如果需要申请更多内存，请参考[这里](https://co1lin.github.io/AIR-Server-Doc/basis/)。

!!! tips "保存 checkpoints 以减少实验进程被杀死后的损失"
